# Working_in-memory_and_with_files

# ğŸ“¥ **Criando Pipelines de Entrada com 'tf.data.Dataset'**

## ğŸ§  Dados em MemÃ³ria

Quando os dados de treino estÃ£o **em memÃ³ria**, use:

- 'tf.data.Dataset.from_tensors'  
  - Agrupa todos os dados em **um Ãºnico elemento** no dataset.

- 'tf.data.Dataset.from_tensor_slices'  
  - Cria **um elemento por linha** do tensor de entrada.

---

## ğŸ“„ Carregando CSV com 'TextLineDataset'

- 'TextLineDataset' carrega dados de **um ou mais arquivos de texto**.
- Cada linha se torna um elemento do dataset.

### Exemplo de uso:
'TextLineDataset(filenames, compression_type=None, num_parallel_reads=None)'

ParÃ¢metros:
- **filenames**: Caminho(s) do(s) arquivo(s)
- **compression_type**: Tipo de compressÃ£o (ex: 'GZIP') â€“ opcional
- **num_parallel_reads**: NÃºmero de leituras paralelas â€“ opcional

---

## ğŸ”„ Parsing de CSV com 'map'

- A funÃ§Ã£o 'map' aplica uma funÃ§Ã£o de parsing em **cada linha do dataset**.
- Essa funÃ§Ã£o retorna um **dicionÃ¡rio** com os dados formatados (ex: features e labels).

---

## ğŸ” Etapas de PrÃ©-processamento

ApÃ³s o parsing, aplique:

- **shuffle** â€“ embaralha os dados (*apenas para treino*)
- **batch** â€“ agrupa os dados em lotes para cada passo de treino
- **prefetch** â€“ prepara o prÃ³ximo lote enquanto o atual Ã© processado

> â— **Importante:** Use uma condiÃ§Ã£o para aplicar 'shuffle' **apenas se o dataset for de treino**.

---

## ğŸ“‚ Trabalhando com Arquivos Fragmentados (Sharded)

Para lidar com grandes conjuntos de dados divididos em vÃ¡rios arquivos:

1. **'tf.data.Dataset.list_files'**  
   - Usa uma sintaxe com wildcard ('*') para localizar arquivos.
   - Retorna um dataset de nomes de arquivos.

2. **'TextLineDataset'**  
   - LÃª as linhas de texto de cada arquivo.

3. **'flat_map'**  
   - Transforma cada nome de arquivo em vÃ¡rias linhas (transformaÃ§Ã£o um-para-muitos).
   - Une todos os datasets resultantes em um Ãºnico stream de dados.

4. **'map'**  
   - Aplica o algoritmo de parsing CSV linha por linha (transformaÃ§Ã£o um-para-um).

---

## ğŸ” DiferenÃ§a entre 'map' e 'flat_map'

| FunÃ§Ã£o        | Caso de uso                                 |
|---------------|----------------------------------------------|
| 'map'         | TransformaÃ§Ãµes **um-para-um** (ex: uma linha â†’ um exemplo) |
| 'flat_map'    | TransformaÃ§Ãµes **um-para-muitos** (ex: um nome de arquivo â†’ vÃ¡rias linhas) |

---

## ğŸš€ Melhorando Performance com 'prefetch'

Sem prefetch:

- A **CPU prepara** o primeiro lote
- A **GPU espera**, depois processa
- SÃ³ entÃ£o a CPU prepara o prÃ³ximo lote

Com **prefetch**:

- Enquanto a GPU estÃ¡ ocupada, a CPU jÃ¡ prepara o **prÃ³ximo lote**
- Isso reduz o tempo ocioso dos dois lados

> âœ… Combine 'prefetch' com **leitura multi-thread e prÃ©-processamento paralelo** para aproveitar ao mÃ¡ximo os recursos de CPU/GPU.

---

## ğŸ¯ ConclusÃ£o

Agora vocÃª sabe como:

- Criar funÃ§Ãµes de entrada com datasets
- Treinar modelos com **datasets grandes fora da memÃ³ria**
- Usar o API 'tf.data' para **transformaÃ§Ãµes e otimizaÃ§Ã£o de desempenho**

> ğŸ“ **Lembrete:** Aproveite toda a flexibilidade da API 'Dataset' para construir pipelines escalÃ¡veis e eficientes.
