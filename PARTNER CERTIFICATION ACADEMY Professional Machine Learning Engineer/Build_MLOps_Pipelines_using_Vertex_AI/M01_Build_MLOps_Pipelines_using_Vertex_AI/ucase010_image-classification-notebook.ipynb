{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ee326-bbbc-4f2d-a178-73c170123a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a1f09-8bc3-4bf8-9b89-7b9322ad7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade --quiet {USER_FLAG} google-cloud-aiplatform kfp google-cloud-pipeline-components==1.0.40 google-cloud-storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c376c2-6dd1-495e-a150-f35f6eddb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04a4c6-411d-4675-a323-24f7df586dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a52dc-b15c-4a5a-ac89-d639d39200a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a28538-1356-4468-902a-7e2e239c4d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION=\"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb2e5f-33f4-4fc6-8911-e326189fd0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BUCKET=PROJECT_ID + \"-bucket\"\n",
    "\n",
    "# set environment variable for reference later.\n",
    "os.environ['REGION']=REGION\n",
    "print(os.getenv('REGION'))\n",
    "\n",
    "os.environ['BUCKET']=BUCKET\n",
    "print(os.getenv('BUCKET'))\n",
    "\n",
    "os.environ['PROJECT_ID']=PROJECT_ID\n",
    "print(os.getenv('PROJECT_ID'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784986a-3137-4bdd-b144-3c7c6a91378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "google-cloud-aiplatform\n",
    "kfp\n",
    "google-cloud-pipeline-components==1.0.40\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e144809-dc7c-42a8-884d-ee2bb4568033",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile pipelines/train_pipeline.py\n",
    "\n",
    "import os\n",
    "\n",
    "import kfp\n",
    "import time\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import component, pipeline, Artifact, ClassificationMetrics, Input, Output, Model, Metrics, Dataset\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from typing import NamedTuple, Dict\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "#Main pipeline class\n",
    "class pipeline_controller():\n",
    "    def __init__(self, template_path, display_name, pipeline_root, project_id, region):\n",
    "        self.template_path = template_path\n",
    "        self.display_name = display_name\n",
    "        self.pipeline_root = pipeline_root\n",
    "        self.project_id = project_id\n",
    "        self.region = region\n",
    "    \n",
    "    def _build_compile_pipeline(self):\n",
    "        \"\"\"Method to build and compile pipeline\"\"\"\n",
    "        self.pipeline = self._get_pipeline(self.project_id, self.region)\n",
    "        compiler.Compiler().compile(\n",
    "            pipeline_func=self.pipeline, package_path=self.template_path\n",
    "        )\n",
    "        \n",
    "    def _submit_job(self):\n",
    "        \"\"\"Method to Submit ML Pipeline job\"\"\"\n",
    "        #Next, define the job:\n",
    "        ml_pipeline_job = aiplatform.PipelineJob(\n",
    "            display_name=self.display_name,\n",
    "            template_path=self.template_path,\n",
    "            pipeline_root=self.pipeline_root,\n",
    "            project=self.project_id,\n",
    "            location=self.region,\n",
    "            # parameter_values={\"project\": self.project_id, \"display_name\": self.display_name},\n",
    "            enable_caching=False\n",
    "        )\n",
    "\n",
    "        #And finally, run the job:\n",
    "        ml_pipeline_job.submit()\n",
    "    \n",
    "    def _get_pipeline(self, PROJECT_ID, REGION):\n",
    "        ## Light weight component to create an Image DS\n",
    "        @component(\n",
    "            base_image=\"python:3.9-slim\",\n",
    "            packages_to_install=[\"google-api-core==2.10.2\", \"google-cloud\", \"google-cloud-aiplatform\", \"typing\", \"kfp\"],\n",
    "        )\n",
    "        def create_ds(project: str, \n",
    "                      display_name: str, \n",
    "                      gcs_source: str, \n",
    "                      import_schema_uri: str, \n",
    "                      timeout: int, \n",
    "                      dataset: Output[Dataset]):\n",
    "\n",
    "            from google.cloud import aiplatform\n",
    "            from google.cloud.aiplatform import datasets\n",
    "            from kfp.v2.dsl import Dataset\n",
    "\n",
    "            aiplatform.init(project=project)\n",
    "\n",
    "            obj_dataset = datasets.ImageDataset.create(\n",
    "                display_name=display_name,\n",
    "                gcs_source=gcs_source,\n",
    "                import_schema_uri=import_schema_uri,\n",
    "                create_request_timeout=timeout,\n",
    "            )\n",
    "\n",
    "            obj_dataset.wait()\n",
    "\n",
    "            dataset.uri = obj_dataset.gca_resource.name\n",
    "            dataset.metadata = {\n",
    "                'resourceName': obj_dataset.gca_resource.name\n",
    "            }\n",
    "        \n",
    "        \"\"\"Main method to Create pipeline\"\"\"\n",
    "        @pipeline(name=self.display_name,\n",
    "                    pipeline_root=self.pipeline_root)\n",
    "        def pipeline_fn(\n",
    "            project: str = PROJECT_ID, \n",
    "            region: str = REGION\n",
    "        ):\n",
    "            \n",
    "            from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "            from google_cloud_pipeline_components.v1.endpoint import (EndpointCreateOp, ModelDeployOp)\n",
    "            import google.cloud.aiplatform as aip\n",
    "\n",
    "            ds_op = create_ds(\n",
    "                project=project,\n",
    "                display_name=\"flowers\",\n",
    "                gcs_source=\"gs://cloud-samples-data/vision/automl_classification/flowers/all_data_v2.csv\",\n",
    "                import_schema_uri=aip.schema.dataset.ioformat.image.single_label_classification,\n",
    "                timeout=3600\n",
    "            )\n",
    "\n",
    "            training_job_run_op = gcc_aip.AutoMLImageTrainingJobRunOp(\n",
    "                project=project,\n",
    "                location=region,\n",
    "                display_name=\"train-automl-flowers\",\n",
    "                prediction_type=\"classification\",\n",
    "                model_type=\"CLOUD\",\n",
    "                dataset=ds_op.outputs[\"dataset\"].ignore_type(),\n",
    "                model_display_name=\"train-automl-flowers\",\n",
    "                training_fraction_split=0.6,\n",
    "                validation_fraction_split=0.2,\n",
    "                test_fraction_split=0.2,\n",
    "                budget_milli_node_hours=8000,\n",
    "            )\n",
    "\n",
    "            endpoint_op = EndpointCreateOp(\n",
    "                project=project,\n",
    "                location=region,\n",
    "                display_name=\"train-automl-flowers\",\n",
    "            )\n",
    "\n",
    "            ModelDeployOp(\n",
    "                model=training_job_run_op.outputs[\"model\"],\n",
    "                endpoint=endpoint_op.outputs[\"endpoint\"],\n",
    "                automatic_resources_min_replica_count=1,\n",
    "                automatic_resources_max_replica_count=1,\n",
    "            )\n",
    "\n",
    "        #Returns as the output of _get_pipeline()\n",
    "        return pipeline_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f7582-c3dd-4849-af18-b64f289d48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BUCKET=PROJECT_ID + \"-bucket\"\n",
    "\n",
    "# set environment variable for reference later.\n",
    "os.environ['REGION']=REGION\n",
    "print(\"REGION: \" + os.getenv('REGION'))\n",
    "\n",
    "os.environ['PROJECT_ID']=PROJECT_ID\n",
    "print(\"PROJECT_ID: \" + os.getenv('PROJECT_ID'))\n",
    "\n",
    "os.environ['BUCKET']=BUCKET\n",
    "print(\"BUCKET: \" + os.getenv('BUCKET'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b7be0-8b1a-4bf7-8431-6abd9bd22482",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile build_and_deploy.py\n",
    "\n",
    "###Code to Build and Deploy the full pipeline\n",
    "###This will be used in Cloud Builder\n",
    "\n",
    "#Initialize pipeline object\n",
    "from pipelines.train_pipeline import pipeline_controller\n",
    "import time\n",
    "import os\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "PROJECT_ID=\"ENTER_YOUR_PROJECT_ID\"  #TODO: Replace the PROJECT_ID variable with Your Project ID\n",
    "BUCKET=f\"{PROJECT_ID}-bucket\"\n",
    "\n",
    "PIPELINE_ROOT = f\"gs://{BUCKET}/pipeline_root/\"\n",
    "DISPLAY_NAME = 'vertex-customml-pipeline{}'.format(str(int(time.time())))\n",
    "\n",
    "print(\"Building pipeline {}\".format(DISPLAY_NAME))\n",
    "\n",
    "pipe = pipeline_controller(template_path=\"pipeline.json\",\n",
    "                           display_name=\"vertex-automlimage-classif\", \n",
    "                           pipeline_root=PIPELINE_ROOT,\n",
    "                           project_id=PROJECT_ID,\n",
    "                           region=REGION)\n",
    "\n",
    "#Build and Compile pipeline\n",
    "pipe._build_compile_pipeline()\n",
    "\n",
    "##Submit Job\n",
    "pipe._submit_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7634c2b9-ef2e-4f30-9b84-04914efbb516",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m build_and_deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0dc884-3870-48f4-89cf-5f411c235406",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "# Download dependencies to /root/.local.\n",
    "FROM python:3.7-slim AS builder\n",
    "COPY requirements.txt .\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f9ade-bea9-48fb-bf1f-688de3bca3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud artifacts repositories create vertex-gar \\\n",
    "    --project=$PROJECT_ID \\\n",
    "    --repository-format=Docker \\\n",
    "    --location=$REGION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60cec43-49e6-4855-88a7-aaf75c85d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cloudbuild.yaml\n",
    "\n",
    "# Create config file and build a new image tagged with the given commit hash.\n",
    "\n",
    "steps:\n",
    "##Step 1 -> Build main image from Dockerfile\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  id: 'build_image'\n",
    "  args: [\n",
    "    'build', '-t', '{REGION}-docker.pkg.dev/{PROJECT_ID}/vertex-gar/latest:latest',\n",
    "    '-f', 'Dockerfile', '.',\n",
    "  ]\n",
    "\n",
    "##Step 2 -> Deploy Docker image to Artifact Repository\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  id: 'push_image'\n",
    "  waitFor:\n",
    "    - 'build_image'\n",
    "  args: [\n",
    "    'push', '{REGION}-docker.pkg.dev/{PROJECT_ID}/vertex-gar/latest:latest'\n",
    "  ]\n",
    "\n",
    "##Step 3 -> Deploy pipeline to Vertex AI( using above built image )\n",
    "- name: '{REGION}-docker.pkg.dev/{PROJECT_ID}/vertex-gar/latest:latest'\n",
    "  id: 'deploy_pipelines'\n",
    "  waitFor:\n",
    "    - 'push_image'\n",
    "  entrypoint: /bin/bash\n",
    "  args:\n",
    "    - -c\n",
    "    - |\n",
    "      python -m build_and_deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b82a4-cc76-4061-89e0-e647997acb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the following command to replace {PROJECT_ID}/{REGION} with project id/region\n",
    "cmd_str_proj = 's/[{]PROJECT_ID[}]/' + PROJECT_ID + '/g'\n",
    "cmd_str_region = 's/[{]REGION[}]/' + REGION + '/g'\n",
    "! sed -i $cmd_str_proj cloudbuild.yaml\n",
    "! sed -i $cmd_str_region cloudbuild.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08866d-de5c-4b83-bd2c-f06a6e37ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit --config=cloudbuild.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d6736-8f9c-4111-9f15-901b3e6a68ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
